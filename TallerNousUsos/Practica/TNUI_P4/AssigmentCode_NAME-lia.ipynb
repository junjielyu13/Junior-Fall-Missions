{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOMS I COGNOMS:\n",
    "\n",
    "GRUP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes i Classificaci√≥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest quart lliurament es programar√† un classificador, que donat un tweet el categoritzar√† en una de les possibles classes. En aquesta ocasi√≥, implementareu un classificador amb tweets de cyber bullying.\n",
    "\n",
    "\n",
    "**Qu√® s‚Äôha de fer?**\n",
    "\n",
    "Volem classificar tweets segons a quin tipus de cyber bullying pertanyen. Aix√≠ doncs, a partir de tots els tweets que tenim, crearem un vector de caracter√≠stiques que ens descrigui cadascun. Finalment desenvoluparem un classificador probabil√≠stic del tipus Naive Bayes que ens permeti identificar a quina classe de cyber bullying pertany un tweet donat segons les caracter√≠stiques triades.\n",
    "\n",
    "\n",
    "**Quina √©s la idea del sistema de classificaci√≥ que s‚Äôha de desenvolupar?**\n",
    "\n",
    "El classificador √©s un concepte de l'aprenentatge autom√†tic supervisat. L'objectiu del classificador √©s donat un vector de caracter√≠stiques que descriuen els objectes que es volen classificar indicar a quina categoria o classe pertanyen d'entre un conjunt predeterminat. \n",
    "\n",
    "El proc√©s de classificaci√≥ consta de dues parts: \n",
    "(a) el proc√©s d'aprenentatge i \n",
    "(b) el proc√©s d'explotaci√≥ o testeig. \n",
    "El proc√©s d'aprenentatge rep exemples de parelles $(x,y)$ on $x$ s√≥n les caracter√≠stiques, usualment nombres reals, i $y$ √©s la categoria a la que pertanyen. \n",
    "Aquest conjunt se'l coneix com a conjunt d'entrenament i ens servir√† per trobar una funci√≥ $\\hat{y}=h(x)$ que donada una $x$ aconsegueixi que $\\hat{y}=y$. Per altra banda el proc√©s de testeig aplica la funci√≥ $h(x)$ apresa a l'entrenament a una nova descripci√≥ per veure quina categoria li correspon.\n",
    "\n",
    "\n",
    "**Classificaci√≥ i llenguatge natural**\n",
    "\n",
    "La descripci√≥ dels exemples en caracter√≠stiques √©s el punt m√©s cr√≠tic de tot sistema d'aprenentatge autom√†tic. \n",
    "Una de les representacions m√©s simples per tal de descriure un text √©s la representaci√≥ *bag-of-words*.\n",
    "Aquesta representaci√≥ converteix un text en un vector de $N$ paraules. \n",
    "Consisteix en seleccionar un conjunt d'$N$ paraules i per cada paraula comptar quants cops apareix en el text. \n",
    "Una versi√≥ alternativa d'aquest proc√©s pot ser simplement indicar si apareix o no en el text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de comen√ßar\n",
    "\n",
    "\n",
    "**\\+ Durant la pr√†ctica, solament es podran fer servir les seg√ºents llibreries**:\n",
    "\n",
    "`Pandas, Numpy` i `NLTK`\n",
    "\n",
    "*Nota: A m√©s de les que ja es troben presents en la 1a cel¬∑la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i par√†metres ja donats**\n",
    "\n",
    "Aix√≤ no implica per√≤ que els h√†giu de fer servir. √âs a dir, que la funci√≥ tingui un par√†metre anomenat `df` no implica que l'h√†giu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica que ser√† i de quin tipus cada un dels par√†metres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posar√† en el pydoc de la funci√≥), `df` sempre ser√† indicatiu del `Pandas.DataFrame` de les dades. Durant els testos, els par√†metres (i espec√≠ficament `df`) no contindran les mateixes dades que en aquest notebook, si b√© si seran del mateix tipus! Per tant, no us refieu de qu√® tinguin, per exemple, el mateix nombre de files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√©s informaci√≥ del dataset\n",
    "\n",
    "El 15 d'Abril de 2020, UNICEF va llan√ßar una alarma com a resposta de l'augment de risc de cyberbullying durant la pand√®mia COVID-19. Les estad√≠stiques s√≥n prou alarmants: un 36.5% dels estudiants de l'escola fins a l'institut s'han sentit v√≠ctimes del cyberbullying i un 87% l'han observat, amb efectes que van des d'una disminuci√≥ de resultats acad√®mics fins a pensaments su√Øcides.\n",
    "\n",
    "Amb l'objectiu d'ajudar a l'analisis de la situaci√≥, s'ha construit un dataset que cont√© m√©s de 47000 tweets etiquetats d'acord amb la classe de cyberbullying que s'est√† donant:\n",
    "\n",
    "1. Age;\n",
    "2. Ethnicity;\n",
    "3. Gender;\n",
    "4. Religion;\n",
    "5. Other type of cyberbullying;\n",
    "6. Not cyberbullying\n",
    "\n",
    "Les dades han estat balancejades per tal de contenir aproximadament 8000 mostres de cada classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llegim dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
       "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cyberbullying_tweets.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion               7998\n",
       "age                    7992\n",
       "gender                 7973\n",
       "ethnicity              7961\n",
       "not_cyberbullying      7945\n",
       "other_cyberbullying    7823\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividim dataset\n",
    "\n",
    "Dividim els tweets en un conjunt d'entrenament, *train*, i en un conjunt de validaci√≥, *test*, per tal de poder entrenar i validar el nostre model de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_tweets_train, df_tweets_test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com les dades estaven balancejades originalment, podem observar que la distribuci√≥ de cadascuna de les classes es mant√©:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion               6437\n",
       "ethnicity              6407\n",
       "not_cyberbullying      6396\n",
       "gender                 6347\n",
       "age                    6338\n",
       "other_cyberbullying    6228\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_train['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    1654\n",
       "gender                 1626\n",
       "other_cyberbullying    1595\n",
       "religion               1561\n",
       "ethnicity              1554\n",
       "not_cyberbullying      1549\n",
       "Name: cyberbullying_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_test['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaci√≥\n",
    "\n",
    "Dividirem el notebook en 3 seccions que es complementen una a l'altra:\n",
    "\n",
    "1. An√†lisis de dades: Informaci√≥ b√†sica sobre els tweets\n",
    "2. Processament de les dades: Creaci√≥ d'un vector de caracter√≠stiques a partir dels tweets\n",
    "3. Classificaci√≥ amb Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. An√†lisis de dades\n",
    "\n",
    "El primer que haurem de fer √©s analitzar les dades per veure una mica com s√≥n. El que us proposem √©s fer una s√®rie de plots per observar dades com ara:\n",
    "\n",
    "* quants tweets s'estan dirigint a una persona en concret\n",
    "* quants hastags hi ha a cada categoria de tweets\n",
    "* quants tweets hi ha de cada categoria\n",
    "* quants tweets de la categoria \"not_cyberbullying\" √©s dirigeixen a un usuari vs totes les altres categories\n",
    "* altres coses que penseu que poden ser rellevants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>@ScottBass because my sunday school had a part...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>@thehiredmind You can have this one. Untag.  T...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>@WyattJamez good stuffüëç</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>@SexKittenParty White feminists need to focus ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45255</th>\n",
       "      <td>RT @SpeakingOfKe_: If a nigga ever talk bad ab...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "7339   @ScottBass because my sunday school had a part...  not_cyberbullying\n",
       "8295   @thehiredmind You can have this one. Untag.  T...             gender\n",
       "1469                             @WyattJamez good stuffüëç  not_cyberbullying\n",
       "2507   @SexKittenParty White feminists need to focus ...  not_cyberbullying\n",
       "45255  RT @SpeakingOfKe_: If a nigga ever talk bad ab...          ethnicity"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 1:** FEU EL VOSTRE ANALISIS DE DADES AQU√ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis(df):\n",
    "    return\n",
    "\n",
    "analisis(df_tweets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptar paraules\n",
    "\n",
    "El primer que haurem d'implementar √©s la funci√≥ *normalize* que normalitzar√† les paraules.\n",
    "\n",
    "\n",
    "No modificar la seg√ºent cel¬∑la, s'encarrega de fer el proce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    class memodict(dict):\n",
    "        def __init__(self, f):\n",
    "            self.f = f\n",
    "        def __call__(self, *args):\n",
    "            return self[args]\n",
    "        def __missing__(self, key):\n",
    "            ret = self[key] = self.f(*key)\n",
    "            return ret\n",
    "    return memodict(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 2:** \n",
    "\n",
    "Empleneu la funci√≥ seg√ºent que, donada una paraula, la normalitzi passant tots els digits a min√∫scules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@memo    \n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Funci√≥ que donada una paraula la normalitzi\n",
    "    Exemple: Taller DELS noUS USOS ---> tallers dels nous usos\n",
    "    \n",
    "    :param word: paraula a normalitzar\n",
    "    :return : paraula normalitzada\n",
    "    \"\"\"\n",
    "    # mantenim nom√©s les lletres i espais\n",
    "    word = ''.join([i for i in word if i.isalpha() or i.isspace()])\n",
    "    # borrem espais dels dos costats i ho passem a minuscula\n",
    "    word = word.lower().strip()\n",
    "   \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'taller dels nous usos'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(' Taller DELS noUS USOS 1###22')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 3:** \n",
    "\n",
    "Feu una funci√≥ que construeixi un diccionari que contingui totes les paraules que s'han trobat tot indicant el total de cops que ha aparegut cadascuna i el nombre de tweets on apareix. M√©s a baix teniu un exemple de l'estructura que ha de tenir el output de la funci√≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@GuysPIctures\n",
      "fuck\n",
      "Lincoln\n",
      "dumb\n",
      "nigger.\n",
      "Lover\n"
     ]
    }
   ],
   "source": [
    "wet = '@GuysPIctures fuck Lincoln dumb nigger. Lover'\n",
    "\n",
    "for word in wet.split():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55986\n"
     ]
    }
   ],
   "source": [
    "def count_words(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de construir un diccionari que contingui totes les paraules que s'han trobat indicant\n",
    "    el total de cops que ha aparegut i el nombre de tweets on apareix\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Diccionari amb el format {word : {n_ocur: valor, n_tweets: valor}, ...}\n",
    "    \"\"\"\n",
    "    word_dicc = {}\n",
    "    visited = set()\n",
    "    \n",
    "    for tweet in df['tweet_text']:\n",
    "        seen_in_tweet = set()\n",
    "        for word in tweet.split():\n",
    "            word = normalize(word)\n",
    "            if word not in visited: \n",
    "                visited.add(word)\n",
    "                # creem un diccionari per la paraula\n",
    "                word_dicc[word] = {}\n",
    "                word_dicc[word]['n_ocur'] = 0\n",
    "                word_dicc[word]['n_tweets'] = 0\n",
    "            if word not in seen_in_tweet:\n",
    "                word_dicc[word]['n_tweets'] += 1\n",
    "                seen_in_tweet.add(word)\n",
    "            word_dicc[word]['n_ocur'] += 1\n",
    "    return word_dicc\n",
    "dicc_text = count_words(df_tweets_train)\n",
    "print(len(dicc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55986\n"
     ]
    }
   ],
   "source": [
    "dicc_text = count_words(df_tweets_train)\n",
    "print (len(dicc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'memory' : {'n_ocur': 88, 'n_tweets': 76},\n",
    "    'best': {'n_ocur': 123, 'n_tweets': 65},\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar paraules per cada categoria de tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>@ScottBass because my sunday school had a part...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>@thehiredmind You can have this one. Untag.  T...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>@WyattJamez good stuffüëç</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>@SexKittenParty White feminists need to focus ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45255</th>\n",
       "      <td>RT @SpeakingOfKe_: If a nigga ever talk bad ab...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "7339   @ScottBass because my sunday school had a part...  not_cyberbullying\n",
       "8295   @thehiredmind You can have this one. Untag.  T...             gender\n",
       "1469                             @WyattJamez good stuffüëç  not_cyberbullying\n",
       "2507   @SexKittenParty White feminists need to focus ...  not_cyberbullying\n",
       "45255  RT @SpeakingOfKe_: If a nigga ever talk bad ab...          ethnicity"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 4:** \n",
    "\n",
    "Fent servir la funci√≥ que se us dona a continuaci√≥ (eachTopic), apliqueu-la per tal de comptar les paraules que s'han trobat i la seva ocurr√®ncia segregant ara per categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group = df.groupby(['cyberbullying_type'])\n",
    "#group.get_group('religion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"words_topic = {}\\n\\noops = df['cyberbullying_type'].iloc[0]\\n#print(oops)\\n\\noo = df['cyberbullying_type'].value_counts()\\nind = oo.index.values\\nprint(ind)\\nprint(type(ind))\\n\\nfor i in ind:\\n    print(i)\\n    group = df.groupby(['cyberbullying_type'])\\n    group = group.get_group(i)\\n    print(group)\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"words_topic = {}\n",
    "\n",
    "oops = df['cyberbullying_type'].iloc[0]\n",
    "#print(oops)\n",
    "\n",
    "oo = df['cyberbullying_type'].value_counts()\n",
    "ind = oo.index.values\n",
    "print(ind)\n",
    "print(type(ind))\n",
    "\n",
    "for i in ind:\n",
    "    print(i)\n",
    "    group = df.groupby(['cyberbullying_type'])\n",
    "    group = group.get_group(i)\n",
    "    print(group)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_words_categories(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de constuir un diccionari que cont√© la freq√º√®ncia de les \n",
    "    paraules i el n√∫mero de tweets on ha aparegut. \n",
    "    Aquesta informaci√≥ ha de ser dividida per diferents categories de cyberbullying.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Diccionari amb el format {label : {word : {n_ocur: valor, n_news: valor} } }\n",
    "    \"\"\"\n",
    "    words_topic = {}\n",
    "    \n",
    "    def eachTopic(group):\n",
    "        # Count words on this topic and save to dictionary\n",
    "        words_topic[group['cyberbullying_type'].iloc[0]] = count_words(group)\n",
    "\n",
    "    # Group by topics and apply function to each topic\n",
    "    \n",
    "    # obtenim els indexos en un array per poder obtenir el nom de cada tipus de cyberbulling\n",
    "    cyberbullings = df['cyberbullying_type'].value_counts().index.values\n",
    "    for cyberbulling in cyberbullings:\n",
    "        group = df.groupby(['cyberbullying_type'])\n",
    "        group = group.get_group(cyberbulling)\n",
    "        eachTopic(group)\n",
    "    \n",
    "    return words_topic\n",
    "\n",
    "words_categories = count_words_categories(df_tweets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "words_categories = count_words_categories(df_tweets_train)\n",
    "print (len(words_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'ethnicity': {\n",
    "        'race' : {'n_ocur': 88, 'n_tweets': 76},\n",
    "        'what': {'n_ocur': 123, 'n_tweets': 65}\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "    'gender': {\n",
    "        'jokes' : {'n_ocur': 18, 'n_tweets': 17},\n",
    "        'you': {'n_ocur': 154, 'n_tweets': 66}\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraules m√©s freq√ºents als tweets\n",
    "\n",
    "\n",
    "**El problema de com escollir el vector de carecter√≠stiques**\n",
    "\n",
    "L'elecci√≥ de les paraules que formen el vector de caracter√≠stiques √©s un pas cr√≠tic. En funci√≥ de com de bona sigui aquesta descripci√≥, millor funcionar√† el sistema. Tot i que us deixem a vosaltres la pol√≠tica de creaci√≥ del vector de caracter√≠stiques us donem una pista: per saber quines paraules fer servir una possible estrat√®gia √©s agafar aquelles paraules que apareixen entre en un 10 i un 50 percent del total (sense tenir en compte la categoria). \n",
    "\n",
    "Podeu experimentar variant aquests valors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 5:** \n",
    "\n",
    "Experimenteu omplint la llista *skip_top* amb aquelles paraules que penseu no tenen significat o relevancia per definir cada categoria. Podeu buscar informaci√≥ sobre **stop words** a internet i definir varies llistes fins que penseu que obteniu una bona representaci√≥ de paraules per categoria de cyberbullying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_top = (\"hi\", \"bye\",\"do\",\"and\",\"to\",\"from\",\"that\",\"i\",\"you\",\"be\",\"her\",\n",
    "           \"some\",\"of\",\"this\",\"would\",\"a\",\"have\",\"make\",\"which\",\"like\",\"as\",\"but\",\n",
    "           \"by\",\"but\",\"with\",\"on\",\"we\",\"say\",\"they\",\"his\",\"my\",\"an\",\"there\",\"what\",\n",
    "           \"up\",\"out\",\"who\",\"get\",\"if\",\"about\",\"when\",\"can\",\"them\",\"also\",\"well\",\n",
    "           \"want\",\"because\",\"our\",\"even\",\"most\",\"us\",\"any\",\"way\",\"the\",\"in\",\"me\",\"was\",\"\",\n",
    "           \"for\",\"are\",\"at\",\"all\",\"she\",\"he\",\"is\",\"it\",\"so\",\"just\",\"not\",\"being\",\"were\",\"its\",\n",
    "           \"got\",\"one\",\"people\",\"im\",\"now\",\"had\",\"middle\",\"how\",\"your\",\"their\",\"done\",\"no\",\n",
    "           \"know\",\"him\",\"never\",\"u\",\"your\",\"dont\",\"or\",\"then\",\"these\",\"into\",\"really\",\"why\",\n",
    "            \"been\",\"first\",\"think\",\"didnt\",\"other\",\"will\",\"did\",\"still\",\"has\",\"mean\",\"go\",\n",
    "            \"years\",\"life\",\"only\",\"always\",\"went\",\"to\",\"every\",\"too\",\"over\",\"more\",\"used\",\"those\",\n",
    "           \"ur\",\"rt\",\"cant\",\"see\",\"going\",\"said\",\"getting\",\"called\",\"past\",\"need\",\"thats\",\n",
    "           \"should\",\"time\")\n",
    "\n",
    "def topNwords(df, words, N, skip=[]):\n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un diccionari amb les N paraules m√©s representatives \n",
    "    (les que apareixen amb m√©s freq√º√®ncia) de cadascuna de les categories de cyberbullying.\n",
    "    \n",
    "    Tingueu en compte que tamb√© haureu de filtrar aquelles paraules que apareixen en la majoria \n",
    "    de tweets, aix√≠ com tamb√©, les que √∫nicament apareixen en un conjunt molt petit de tweets\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :param words: diccionari amb les paraules i la seva frequencia\n",
    "    :param N: n√∫mero de paraules m√©s representatives que volem considerar\n",
    "    :return : Diccionari amb el format {categoria1: llista_top_words_cat_1,  \n",
    "                                        categoria2: llista_top_words_cat_2, ...} \n",
    "    \"\"\"\n",
    "    top_words=dict()\n",
    "    \n",
    "    def each_word(topic, word):\n",
    "        if word not in skip:\n",
    "            return words[topic][word]['n_ocur']\n",
    "        return 0\n",
    "    \n",
    "    for topic in words:\n",
    "        top_words[topic] = sorted(words[topic], key=lambda x: each_word(topic, x))[-N:][::-1]\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = topNwords(df_tweets_train, words_categories, 20, skip_top)\n",
    "#top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'age': ['school', 'high', ...],\n",
    "    ...\n",
    "    'religion': ['muslims', 'christian',...]\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Una pista de que aneu ben encaminats es que per cadascuna de les categories de cyberbullying obtingueu paraules rellevants per aquesta. Si no es aix√≠, vol dir que heu d'incrementar el nombre de paraules a saltar (*skip_top*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> EXPERIMENTEU AQU√ç QU√à PASSA SEGONS LES \"STOP WORDS\" QUE USEU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector de Caracter√≠stiques\n",
    "\n",
    "#### **EXERCICI 6:** \n",
    "\n",
    "Creeu el vector de caracter√≠stiques necessari per a fer l‚Äôentrenament del Na√Øve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for index,tweet in enumerate(df['tweet_text']):\\n    print(tweet)\\n    print(index)\\n    break\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for index,tweet in enumerate(df['tweet_text']):\n",
    "    print(tweet)\n",
    "    print(index)\n",
    "    break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"words = []\\nfor frequent_words in pd.Series(top_words).values:\\n    for word in frequent_words:\\n        if word not in words:\\n            words.append(word)\\nwords = np.array(words)\\n#print(words)\\n\\ndef tweet_normalized(tweet):\\n    words = set()\\n    for word in tweet.split():\\n        words.add(normalize(word))\\n    return words\\n\\na_tweet = df['tweet_text'][0]\\nprint(a_tweet)\\n\\nnorm = tweet_normalized(a_tweet)\\nprint(norm)\\n\\nllista = np.zeros((len(words),), dtype=int)\\nprint(llista)\\nfor index,word in enumerate(words):\\n    if word in norm:\\n        llista[index] = 1\\n        \\nprint(llista)\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"words = []\n",
    "for frequent_words in pd.Series(top_words).values:\n",
    "    for word in frequent_words:\n",
    "        if word not in words:\n",
    "            words.append(word)\n",
    "words = np.array(words)\n",
    "#print(words)\n",
    "\n",
    "def tweet_normalized(tweet):\n",
    "    words = set()\n",
    "    for word in tweet.split():\n",
    "        words.add(normalize(word))\n",
    "    return words\n",
    "\n",
    "a_tweet = df['tweet_text'][0]\n",
    "print(a_tweet)\n",
    "\n",
    "norm = tweet_normalized(a_tweet)\n",
    "print(norm)\n",
    "\n",
    "llista = np.zeros((len(words),), dtype=int)\n",
    "print(llista)\n",
    "for index,word in enumerate(words):\n",
    "    if word in norm:\n",
    "        llista[index] = 1\n",
    "        \n",
    "print(llista)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(df, top_words): \n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un vector de caracter√≠stiques necessari per a l'entrenament del classificador Naive Bayes\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params top_words: ha de ser el diccionari que retorna topNWords\n",
    "    :return : diccionari o pd.Series que cont√© un np.array per a \n",
    "        cadascuna dels tweets amb el vector de caracter√≠stiques corresponent.\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_feat_vector = {}\n",
    "    \n",
    "    # creem el vector de caracter√≠stiques amb totes les paraules freq√ºents\n",
    "    words = []\n",
    "    for frequent_words in pd.Series(top_words).values:\n",
    "        for word in frequent_words:\n",
    "            if word not in words:\n",
    "                words.append(word)\n",
    "    words = np.array(words)\n",
    "    \n",
    "    def tweet_normalized(tweet):\n",
    "        words = set()\n",
    "        for word in tweet.split():\n",
    "            words.add(normalize(word))\n",
    "        return words\n",
    "    \n",
    "    # analitzem cada tweet i mirem si cada paraula del tweet esta en la nostra llista de paraules freq√ºents\n",
    "    for index,tweet in enumerate(df['tweet_text']):\n",
    "        for i,word in enumerate(words):\n",
    "            # inicialitzem\n",
    "            if i == 0:\n",
    "                dict_feat_vector[index] = np.zeros((len(words),), dtype=int)\n",
    "            if word in tweet_normalized(tweet):\n",
    "                dict_feat_vector[index][i] = 1\n",
    "       \n",
    "    return dict_feat_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 20 # Aquest parametre el podem canviar i fer proves per avaluar quin √©s el millor valor. \n",
    "words_categories = count_words_categories(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_categories, N, skip_top)\n",
    "dict_feat_vector = create_features(df_tweets_train, top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "len(dict_feat_vector)\n",
    "print(dict_feat_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38153"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_feat_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    0: np.array([0, 1, 1, 0, ...]),\n",
    "    1: np.array([0, 1, 1, 1, ...]),\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com podem observar, hi ha un vector de caracter√≠stiques per cadascun dels tweets en entrenament. El que esperem √©s que aquest vector ens estigui donant informaci√≥ del que posa a cada tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38153, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicar l aformula tweet representado con el vector\n",
    "# cad una de las x, es independeinte las otras, seria multiplicar da cuna de lsa prob marginles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El classificador Na√Øve Bayes\n",
    "\n",
    "Un cop tenim una representaci√≥ necessitem un proc√©s d'aprenentatge que ens permeti passar de la descripci√≥ a una categoria. \n",
    "En aquest lliurament farem servir el classificador Na√Øve Bayes. \n",
    "Aquest classificador forma part de la fam√≠lia de classificadors probabil√≠stics. \n",
    "La sortida d'un classificador probabil√≠stic √©s un valor de probabilitat donat un exemple per cadascuna de les categories. \n",
    "La decisi√≥ final correspon a la categoria amb m√©s probabilitat. \n",
    "\n",
    "\n",
    "Els classificadors probabilistics Bayesians es basen en el teorema de Bayes per realitzar els c√†lculs per trobar la probabilitat condicionada: \n",
    "$$ p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "d'on podem extreure que: \n",
    "$$ p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$\n",
    "\n",
    "\n",
    "En molts casos $p(y)$ i $p(x)$ s√≥n desconeguts i es consideren equiprobables. \n",
    "Per tant, la decisi√≥ es simplifica a:\n",
    "$$ p(y|x) = p(y) ¬∑ p(x|y)$$\n",
    "\n",
    "\n",
    "Les deduccions fins a aquest punt s√≥n v√†lides per la majoria de classificadors Bayesians. \n",
    "Na√Øve Bayes es distingeix de la resta perqu√® imposa una condici√≥ encara m√©s restrictiva. \n",
    "Considerem $x=(x_1, \\cdots, x_n)$ un conjunt d'$N$ variables aleat√≤ries. \n",
    "Na√Øve Bayes assumeix que totes elles s√≥n independents entre elles i per tant podem escriure:\n",
    "$$p(x_1,x_2,...,x_N | y) = p(x_1|y)p(x_2|y)...p(x_N|y)$$\n",
    "\n",
    "\n",
    "Podem interpretar l'anterior equaci√≥ de la seg√ºent forma: La probabilitat de que el tweet descrit pel vector de caracter√≠stiques (0,1,0,1,1,1) sigui de la classe \"gender\" √©s proporcional al producte de la probabilitat que la primera paraula del vector no aparegui en els tweets sobre \"gender\" per la probabilitat que la segona paraula s√≠ que hi aparegui, etc.\n",
    "\n",
    "\n",
    "**Estimant les probabilitats marginals condicionades**\n",
    "\n",
    "L'√∫ltim pas que ens queda √©s trobar el valor de les probabilitats condicionades. \n",
    "Farem servir la representaci√≥ de $0$'s i $1$'s indicant que la paraula no apareix (0) o s√≠ apareix (1) a al tweet. \n",
    "Per trobar el valor de la probabilitat condicionada farem servir una aproximaci√≥ freq√ºentista a la probabilitat. \n",
    "Aix√≤ vol dir que calcularem la freq√º√®ncia d'aparici√≥ de cada paraula per a cada categoria. \n",
    "Aquest c√†lcul es fa dividint el nombre de tweets de la categoria en que apareix la paraula pel nombre total de tweets d'aquella categoria. \n",
    "\n",
    "En gneral:\n",
    "$$p(x = \\text{\"school\"} | y = C)= \\frac{A}{B} $$\n",
    "on A √©s el n√∫mero de tweets de la categoria C on hi apareix la paraula 'school' i B √©s el n√∫mero total de tweets de la categoria C.\n",
    "\n",
    "\n",
    "### Punts d√®bils:\n",
    "\n",
    "**El problema de la probabilitat 0**\n",
    "\n",
    "Si us hi fixeu b√©, la probabilitatpot ser 0 !!  Aix√≤ vol dir, que si en el tweet no hi apareix una paraula no pot ser classificada com cap tipus de cyber bullying.\n",
    "\n",
    "No sembla raonable que s'assigni o no en aquesta categoria segons si en el tweet hi apareix o no una √∫nica paraula. \n",
    "Per tant, el que s'acostuma a fer √©s donar una baixa probabilitat en comptes de zero. \n",
    "Una de les possibles solucions es fer servir la correcci√≥ de Laplace. \n",
    "Seguint l'exemple anterior la correcci√≥ de Laplace √©s\n",
    "$$p(x= \\text{\"school\"} | y = 'C' ) = \\frac{A+1}{B+M}$$ \n",
    "on M √©s el nombre de categories\n",
    "\n",
    "**El problema del \"underflow\"**\n",
    "\n",
    "La funci√≥ que hem de calcular en el Naive Bayes √©s un producte. \n",
    "El nombre de caract√©ristiques del vector √©s el nombre de termes del producte. \n",
    "Aquests nombres s√≥n iguals o menors a 1, si els multipliquem tots entre ells el resultat ser√† massa petit per a representar-lo en un nombre de punt flotant i el c√†lcul acabar√† sent redu√Øt a zero. \n",
    "Per solucionar aquest problema en comptes d'operar fent multiplicacions, se sol passar a l'escala logar√≠tmica i all√† operar fent servir sumes en comptes de multiplicacions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EXERCICI 7:** \n",
    "\n",
    "Implementeu la funci√≥ d'aprenentatge del classificador Na√Øve Bayes (funci√≥ **naive_bayes_learn()**). La funci√≥ ha de mostrar per pantalla el resultat obtingut \n",
    "L'**error d'entrenament** es troba calculant el percentatge d'errors que s'obtenen quan es fa el testeig amb les mateixes dades utilizades per fer entrenament (aprenentatge). Aquest error es un valor molt optimista de com funcionar√† el clasificador i mai s'ha de prendre com a mesura per comparar clasificadors. \n",
    "\n",
    "1) Programeu la funci√≥ **naive_bayes_learn** per a que estimi les probabilitats marginals condicionades.\n",
    "2) Programeu la funci√≥ **naive_bayes** que implementa el classificador. Noteu que aquesta funci√≥ est√° guiada i nom√©s haureu d'emplenar els espais on hem posat tres punts suspensius \"#¬∑¬∑¬∑\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_learn(df, feats):\n",
    "    \"\"\"\n",
    "    Funci√≥ que estima les probabilitats marginals condicionades.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params feats: vector de caracter√≠stiques de cada tweet\n",
    "    :return : probabilitats marginals condicionades\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython import embed\n",
    "def naive_bayes(df_train, feat_train, feat_test=None, df_test=None):\n",
    "    \"\"\"\n",
    "    Funci√≥ que implementa el clasificador Naive_Bayes.\n",
    "    \n",
    "    Si df_test no √©s None, ha de calcular l'encert sobre les dades de test. √âs a dir,\n",
    "    despr√©s de classificar feat_test ha de comparar la classificaci√≥ amb la classe\n",
    "    real i dir (print) quin percentatge d'encert ha obtingut.\n",
    "    \n",
    "    :param df_train: DataFrame amb els tweets que s'utilitzaran per l'entrenament\n",
    "    :param feat_train: Diccionari amb els vectors de caracteristiques de cada tweet de l'entrenament\n",
    "    :param feat_test: Diccionari amb els vectors de caracteristiques de cada tweet de test\n",
    "    :param df_test: DataFrame amb els tweets que s'utilitzaran pel test\n",
    "    \n",
    "    :return : Una serie on l'index correspon amb els indexos de df_test i els valors s√≥n la\n",
    "        classificaci√≥ retornada per Naive Bayes\n",
    "    \"\"\"\n",
    "    probs = naive_bayes_learn(df_train, feat_train)\n",
    "    p_of_cat = count_words_categories(df_train)\n",
    "    p_total = len(p_of_cat.keys())\n",
    "    \n",
    "    def eachFeats(row):\n",
    "        id, feat = row\n",
    "        p_max = float('-inf')\n",
    "        p_cat = 0\n",
    "\n",
    "        for category in probs:\n",
    "            # Speed up by using numpy\n",
    "            # inv is the inverse of features, 0 where 1 and 1 where 0\n",
    "            # ...\n",
    "            \n",
    "            # Probs * feats is the probability of being there, while\n",
    "            # inv - inv * feat = 1 - (0, 1, 0... inverses) * probs, probability of not being there\n",
    "            # ...\n",
    "            \n",
    "            # Sum of logs [vs] underflow caused by mul of probs\n",
    "            # ...\n",
    "\n",
    "            # Take the max, do it now to avoid extra-loops\n",
    "            # ...\n",
    "                \n",
    "        return id, p_cat\n",
    "    \n",
    "    data = map(eachFeats, feat_test.items())\n",
    "    data = pd.Series(dict(data))\n",
    "    correct = data == df_test['cyberbullying_type']\n",
    "    print(\"Accuracy: {}\".format(correct.sum() / correct.size))\n",
    "    \n",
    "    return correct.sum() / correct.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 # Aquest parametre el podem canviar i fer proves per avaluar quin √©s el millor valor. \n",
    "words_topics = count_words_categories(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_topics, N, skip_top)\n",
    "\n",
    "feat_train = create_features(df_tweets_train, top_words)\n",
    "feat_test = create_features(df_tweets_test, top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6931544187021701\n"
     ]
    }
   ],
   "source": [
    "accuracy = naive_bayes(df_tweets_train, feat_train, feat_test, df_tweets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haurieu d'obtenir una accuracy del 69-70%. Si heu arribat a aix√≤ ja est√† b√©! \n",
    "\n",
    "En canvi, per aquells que vulguin tenir alguns **PUNTS EXTRA**, us retem a aconseguir una accuracy m√©s alta. A veure qu√® podeu fer!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPLEMENTACI√ì DE MILLORA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
