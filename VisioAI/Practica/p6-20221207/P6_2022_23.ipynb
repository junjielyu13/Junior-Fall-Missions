{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a816d3",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "# Practicum 6 \n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9901d7",
   "metadata": {},
   "source": [
    "##Â Delivery\n",
    "\n",
    "Up to **1 point out of 10** will be penalized if the following requirements are not fulfilled:\n",
    "\n",
    "- Implemented code should be commented.\n",
    "\n",
    "- The questions introduced in the exercises must be answered.\n",
    "\n",
    "- Add title to the figures to explain what is displayed.\n",
    "\n",
    "- Comments need to be in **english**.\n",
    "\n",
    "- The deliverable must be a file named **P6_Student1_Student2.zip** that includes:\n",
    "    - The notebook P6_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "    - All the images used in this notebook.\n",
    "\n",
    "**Deadline: December 22th, 23:00 h**\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d19642",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8e2cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "\n",
    "# Split dataset into training and test\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "### FACE DETECTION\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.feature import haar_like_feature_coord\n",
    "from skimage.feature import draw_haar_like_feature\n",
    "from skimage.transform import integral_image\n",
    "\n",
    "### FACE RECOGNITION\n",
    "# Load the dataset\n",
    "from sklearn.datasets import fetch_lfw_people \n",
    "# Classification and results\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d51200",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Haar-like features applied for face detection\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62468675",
   "metadata": {},
   "source": [
    "### What is a Haar-like feature?\n",
    "\n",
    "Haar-like feature descriptors were successfully used to implement the first real-time face detector. In this laboratory we will see an example illustrating the extraction, selection, and classification of Haar-like features to detect faces vs. non-faces.\n",
    "\n",
    "Documentation [Haar-like feature skimage](https://scikit-image.org/docs/0.14.x/auto_examples/xx_applications/plot_haar_extraction_selection_classification.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b5ae3",
   "metadata": {},
   "source": [
    "Haar-like features are features extracted from the images to recognize objects. These features are normally used in face recognition. The key to face recognition is to detect the relevant features of humans such as eyes, lips, or nose. \n",
    "\n",
    "\n",
    "<img src=\"notebook_images/haar-like.PNG\" width=400, height=400>\n",
    "\n",
    "Try to guess where in the face image we expect to detect an edge, line or another facial feature and what would be the most appropriate Haar-feature for them? \n",
    "\n",
    "<img src=\"notebook_images/haar-like1.PNG\" width=500, height=500>\n",
    "\n",
    "\n",
    "A real application would be:\n",
    "\n",
    "<img src=\"notebook_images/face.PNG\" width=300, height=300>\n",
    "\n",
    "\n",
    "To describe the face, we can apply convolutions with Haar features. What alternative to the convolution with Haar-features, do you know?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85eb7b0",
   "metadata": {},
   "source": [
    "### 1. Building integral image\n",
    "\n",
    "Compute all the Haar-like features (we can define up to 16000 million masks), can be a slow process. To compute it faster, we are going to use the integral images (instead of convolutions). It is very useful because we are able to save all the sums and substrations of image rectangles to avoid computing all the features every time.\n",
    "\n",
    "When creating an Integral Image, we need to create a Summed Area Table. What does represent any point (x,y) in this table?\n",
    "\n",
    "<img src=\"notebook_images/integral_image.PNG\" width=250, height=2500>\n",
    "\n",
    "An example :\n",
    "\n",
    "<img src=\"notebook_images/integral_image1.PNG\" width=400, height=400>\n",
    "\n",
    "To easy the computation of Haar features, the integral image must have an additional row and column full of zeros (first row and first column). Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853edd8f",
   "metadata": {},
   "source": [
    "**1.1** Build a function `to_integral_image` that computes the integral image of an input (2D) array. The integral image must have an additional row and column full of zeros (first row and first column).\n",
    "Make sure that the values of the integral image are correct.\n",
    "\n",
    "Try your function using a `5x5` random grayscale image. Visualize both the original random image and the integral one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f672dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e3364",
   "metadata": {},
   "source": [
    "To make sure that the values of the integral image are correct, compute the following tests:\n",
    "\n",
    " - `img_array.sum() == ii_img_array[-1,-1]`\n",
    " - `img_array[0,:].sum() == ii_img_array[1,-1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5f3bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ba062",
   "metadata": {},
   "source": [
    "**1.2** Let's check in real images. Choose an image from the directory ``./faces``, visualize both the original and the integral image, and make the same test that in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a13ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55926ef5",
   "metadata": {},
   "source": [
    "What do the following lines mean? How can you explain this?\n",
    "\n",
    "- `img_array.sum() == ii_img_array[-1,-1]`\n",
    "- `img_array[0,:].sum() == ii_img_array[1,-1]`\n",
    "- `ii_img_array[0,-1].sum() == 0`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f9d3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cdcc4b",
   "metadata": {},
   "source": [
    "**1.3:** Alternatively to your own function, you can use the ``integral_image()`` function from ``skimage.transform``. Compare (numerically) the result obtained using your funtion and that obtained using the function provided by skimage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f33e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5159a1",
   "metadata": {},
   "source": [
    "## 2. Haar-like features\n",
    "\n",
    "Let's use the [haar_like_feature()](https://scikit-image.org/docs/0.14.x/api/skimage.feature.html#skimage.feature.haar_like_feature) function from skimage. Check the parameters and the returned value of the ``function haar_like_feature()`` before continuing and **NOTE** that we must use the integral image (**not the real image**) in this function.\n",
    "\n",
    "*skimage.feature.haar_like_feature(int_image, rint, cint, widthint, heightint, feature_type=None, feature_coord=None)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac72bf",
   "metadata": {},
   "source": [
    "###  Extract features\n",
    "\n",
    "**2.1** Define a function ``extract_feature_image(image, feature_type, feature_coord=None)`` to obtain the Haar-like features, using a given type of features ``feature_types``, from an image. The aim of this function is as simple as to join both `to_integral_image()` and `haar_like_feature()`functions.\n",
    "\n",
    "Try your function using the choosing image from *1.4*. You should obtain a feature vector. Print the vector shape.\n",
    "\n",
    "**Note:** You can give an array with a set of feature types to the `haar_like_feature()` function and it will compute all the corresponding features. We **do not** need to give each time only one feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "473237ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = ['type-2-x', 'type-2-y',\n",
    "                 'type-3-x', 'type-3-y',\n",
    "                 'type-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68120e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7d536",
   "metadata": {},
   "source": [
    "**2.2** Plot a Haar-like feature on an image:\n",
    "\n",
    "To visualize Haar-like features on an image, we need the fuctions, provided by skimage, ``haar_like_feature_coord()``, which computes the coordinates of Haar-like features, and ``draw_haar_like_feature()``, used to visualize that features.\n",
    "\n",
    "Before continuing, please, **check the online documentation of the two functions**\n",
    "\n",
    "- [*haar_like_feature_coord(width, height, feature_type=None)*](https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.haar_like_feature_coord)\n",
    "\n",
    "- [*draw_haar_like_feature(image, r, c, width, height, feature_coord, color_positive_block=(1.0, 0.0, 0.0), color_negative_block=(0.0, 1.0, 0.0), alpha=0.5, max_n_features=None, random_state=None)*](https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.draw_haar_like_feature)\n",
    "\n",
    "Define a function ``plotFeatures``  to visualize Haar-like features on an images, given a array of feature types ``feature_types``. The aim of this exercise is, similarly to the previous one, to merge both `haar_like_feature_coord()` and `draw_haar_like_feature()` functions. Try your own function using the choosing image from *1.4* as follows:\n",
    "\n",
    "<img src=\"notebook_images/image1.png\" width=600, height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45b175ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1caa4",
   "metadata": {},
   "source": [
    "## 3 Face detection using an Adaboost\n",
    "\n",
    "**3.1** Read all the images from the directories ``./faces`` and ``./nonfaces`` and build an array with the all the features. \n",
    "\n",
    "Futhermore, build the class labels vector ``y`` with the label of all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "67217782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f2933b",
   "metadata": {},
   "source": [
    "**3.2** Using the ``train_test_split()`` function from `sklearn.model_selection`, divide the dataset into *train* and *test* sets. The test size must be the 30% (i.e. 0.3) of the whole dataset.\n",
    "\n",
    "[*sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ec6fd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ae2d6",
   "metadata": {},
   "source": [
    "**3.3** Train an Adaboost classifier using `AdaBoostClassifier()`from `sklearn.ensemble`.\n",
    "\n",
    "[*sklearn.ensemble.AdaBoostClassifier(n_estimators=50, learning_rate=1.0)*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "\n",
    "What is an Adaboost? How it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6de49ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a47946",
   "metadata": {},
   "source": [
    "**3.4** Evaluate the accuracy of the Adaboost classifier using the *predict* and *score* methods of the classifier. What are these methods doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "89e2990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a666199",
   "metadata": {},
   "source": [
    "Change the parameter ``n_estimators`` and see what happens. Does it improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b9f8639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b20bad",
   "metadata": {},
   "source": [
    "**3.5** The method ``feature_importances_`` of the Adaboost is giving the importance of the features. Implement a function to visualize the 10 most important features on an image of a face on your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "40351eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f17ab1",
   "metadata": {},
   "source": [
    "**3.6 (Optional)** Implement the Adaboost training the model using a different number of features. For instace,  just using 1 type of feature, 2 types, and 3 types. Plot the results comparing the precision. Draw conclusions about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4bae45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6d883",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Principal Component Analysis (PCA) applied for face recognition\n",
    "==============================================================================================\n",
    "\n",
    "### Dimensionality and redundancy\n",
    "\n",
    "Imagine we have a dataset with 100x100 pixel images, it means we have 10000 dimensions. We want to construct a low-dimensional linear subspace that best explains the variation in the set of face images (**Eigenfaces space**)\n",
    "\n",
    "<img src=\"notebook_images/subspace.PNG\" width=200, height=200>\n",
    "\n",
    "Each image has m rows and n columns and defines a vector of (mxn) elements. We need to choose the most valuable pixels in order to avoid compute all dimensions. \n",
    "\n",
    "<img src=\"notebook_images/feature_vector.PNG\" width=800, height=400>\n",
    "\n",
    "We look for a transformation of the original space to a smaller (M << (mxn)) where faces are represented with their coordinates in this new space R.\n",
    "\n",
    "To reduce the dimensionality retaining the information necessary to classify and recognize, we are going to use the **Eigenfaces method** \n",
    "\n",
    "### How to build a reduced space?\n",
    "\n",
    "To build this new space, we are going to use the **Principal Component Analysis**. Given a large space, the PCA looks for the minimum number of axes that best represents the variation of the data.\n",
    "\n",
    "<img src=\"notebook_images/pca.PNG\" width=400, height=400>\n",
    "\n",
    "The eigenvectors of the covariance matrix define the axis of maximum variance and the eigenvalues give a measure of the variance of the data. \n",
    "\n",
    "1. Construct the vector in the (m x n)-dimensional space R given M images of size (m x n).\n",
    "\n",
    "2. Compute the mean image \n",
    "\n",
    "<center>\n",
    "$\\overline{X}=\\frac{1}{M}\\sum_{i=1}^{M} X_i$\n",
    "</center>\n",
    "\n",
    "3. Construct the covariance matrix. Due to $A \\times A^T$ is too large, instead of using $A \\times A^T$ to compute its eigenvectors, we are going to compute the eigenvectors of $A^T \\times A$.\n",
    "\n",
    "<img src=\"notebook_images/covariance_image.PNG\" width=500, height=500>\n",
    "\n",
    "4. Extract the eigenvectors (the base of the new space) and their eigenvalues and project faces in the new space to apply the classifier (knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998341f",
   "metadata": {},
   "source": [
    "## 4. Load and prepare data\n",
    "\n",
    "Let's use the [Labeled Faces in the Wild (LFW)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html) people dataset (classification).\n",
    "\n",
    "Face dataset features:\n",
    "\n",
    "- Classes: 5749\n",
    "\n",
    "- Samples total: 13233\n",
    "\n",
    "- Dimensionality: 5828\n",
    "\n",
    "- Features: real, between 0 and 255\n",
    "\n",
    "\n",
    "*sklearn.datasets.fetch_lfw_people(data_home=None, funneled=True, resize=0.5, min_faces_per_person=0, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True, return_X_y=False)*\n",
    "\n",
    "\n",
    "\n",
    "*Please, check the parameters and returned value by ``lethc_lfw_people()`` before continuing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08ace7",
   "metadata": {},
   "source": [
    "**4.1** Load the dataset, obtaining only those cases where there are, at least, 100 images. Check the final number of images, image shapes and labels of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d901e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8538b",
   "metadata": {},
   "source": [
    "**4.2** Plot an image frome each example, with its name as the title of the image.\n",
    "\n",
    "<img src=\"notebook_images/example.png\" width=500, height=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c69c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077941cd",
   "metadata": {},
   "source": [
    "**4.3** Divide the dataset into train and test set (0.7/0.3). \n",
    "\n",
    "Hint: use the train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7835cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc42f97",
   "metadata": {},
   "source": [
    "## 5. Compute PCA\n",
    "\n",
    "[*class sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None)*](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?highlight=pca#sklearn.decomposition.PCA)\n",
    "\n",
    "The principal components measure deviations about this mean along orthogonal axes.\n",
    "\n",
    "**5.1** Create a PCA object, using the training set and a 150 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349d67f2",
   "metadata": {},
   "source": [
    "Plot the accumated variance of the components. \n",
    "\n",
    "**Hint:** Use the returned `explained_variance_ratio_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639bc0c2",
   "metadata": {},
   "source": [
    "**5.2** One interesting part of PCA is that it computes the average face, which can be interesting to examine. \n",
    "\n",
    "Plot the average face, using the method `mean_` of the PCA object.\n",
    "\n",
    "**Hint:** The average face need to be reshaped in order to visualize it properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca20ab",
   "metadata": {},
   "source": [
    "**5.3** Furhtermore, we can check all the principal components (i.e. eigenfaces) considering the corresponding importance. Visualize 30 principal eigenfaces.\n",
    "\n",
    "<img src=\"notebook_images/eigenfaces.png\" width=500, height=500>\n",
    "\n",
    "Note that the base components are ordered by their importance. We see that the first few components seem to primarily take care of lighting conditions; the remaining components pull out certain identifying features: the nose, eyes, eyebrows, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e9c1a",
   "metadata": {},
   "source": [
    "**5.4** Project both the training and test set onto the PCA basis, using the method `transform()` of the PCA object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc757a0",
   "metadata": {},
   "source": [
    "Do you need to apply the same to the variable y?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8736dea",
   "metadata": {},
   "source": [
    "**5.5**  These projected components correspond to factors in a linear combination of component images such that the combination approaches the original face. \n",
    "\n",
    "Choose one of the images and try to recompose from its first 10 most important corresponding eigenfaces. **Note that** we need to use the average face as the basis to agregate the rest of the components.\n",
    "\n",
    "\n",
    "<img src=\"notebook_images/eigenfaces_image.PNG\" width=300, height=300>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b02b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03ca6e",
   "metadata": {},
   "source": [
    "## 6. Train a classifier\n",
    "\n",
    "**6.1** Train an Adaboost classifier using the PCA features. Show the results obtained with the test set.\n",
    "Use the `score` method of the Adaboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5e894",
   "metadata": {},
   "source": [
    "**6.2** We can quantify this effectiveness using one of several measures from sklearn.metrics. First we can do the classification report, which shows the precision, recall and other measures of the âgoodnessâ of the classification.\n",
    "\n",
    "*sklearn.metrics.classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')*\n",
    "\n",
    "*Please, check the parameters and returned value by ``classification_report()`` before continuing.*\n",
    "\n",
    "Print the classification report obtained during the training of the Adaboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0580b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f73e3",
   "metadata": {},
   "source": [
    "Please, explaing what is:\n",
    "- accuracy (score)\n",
    "- precision\n",
    "- recall\n",
    "- f1-score\n",
    "- support\n",
    "- macro avg\n",
    "- weighted avg?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d25e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7ef4240",
   "metadata": {},
   "source": [
    "**6.3** Train an Adaboost classifier, without PCA, using the training set. Show the results using the `score` method of the Adaboost model and the corresponding classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b45be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b47f6",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "- Does computing time change using PCA? How?\n",
    "- Which of both (with and without PCA) does give better results?\n",
    "- How does the result change if we change the number of components in PCA?\n",
    "- How does the result change if we change the number of estimators in the Adaboost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eaf75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07ca575d",
   "metadata": {},
   "source": [
    "**6.4 (Optional)** Repeat the experiment using a different number of components. \n",
    "\n",
    "For instance, instead of using 150 components, try using 10, 25, 50, 200, 500... at your election. These numbers are just orientative. \n",
    "\n",
    "- How much variance is acummulated using the different number of components.\n",
    "- The result is better using... how many components? \n",
    "- Does time change using a different numbero of components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb6c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e5feff0",
   "metadata": {},
   "source": [
    "## 7. Recognize a new face example using the learned model\n",
    "\n",
    "**7.1** Try your both models using the test set. \n",
    "\n",
    "Predict the labels using the Adaboost model, with and without PCA, and plot the images with the corresponding label as title.\n",
    "\n",
    "<img src=\"notebook_images/prediction.png\" width=300 height = 300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f781be",
   "metadata": {},
   "source": [
    "Which model makes the predictions betters? Try different parameters and comment their effect on the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907defdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b2d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
