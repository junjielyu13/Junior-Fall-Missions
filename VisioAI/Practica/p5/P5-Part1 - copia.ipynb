{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "# Practicum 5 - Part 1\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##¬†Delivery\n",
    "\n",
    "Up to **1 point out of 10** will be penalized if the following requirements are not fulfilled:\n",
    "\n",
    "- The questions introduced in the exercises must be answered.\n",
    "\n",
    "- Implemented code should be commented.\n",
    "\n",
    "- Add title to the figures to explain what is displayed.\n",
    "\n",
    "- Comments need to be in **english**.\n",
    "\n",
    "- The deliverable must be a file named **P5_Student1_Student2.zip** that includes:\n",
    "    - The notebook P5_Student1_Student2.ipynb completed with the solutions to the exercises and their corresponding comments.\n",
    "\n",
    "**Deadline: December 6th, 23:00 h**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "##  Image search using textures\n",
    "==============================================================================================\n",
    "\n",
    "#### Problem we want to solve\n",
    "- Given a query image **$x$** and a set of images **$X$** we would like to retreive the most similar to **$x$** images from  **$X$**.\n",
    "\n",
    "The exercises of this notebook will show how we can perform image similarity search using:\n",
    "\n",
    "- Gaussian filters\n",
    "- Descriptors based on texture \n",
    "- Distance between images and similarity search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import filters\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray, rgba2rgb\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Derivative of Gaussians aka Leung-Malik (LM) Filter Bank\n",
    "We can apply a collection of multiple filters that we call a filter bank. Note that if we apply $D$ filters our feature vectors will be $D$ dimensional.\n",
    "\n",
    "The following image shows a filter bank. In the filter bank we typically want filters to capture a combination of scales, orientations of different types of patterns. This particular filter bank is The Derivative-of-Gaussians or as known as Leung-Malik (LM) Filter Bank.\n",
    "\n",
    "<img src=\"./images_notebook/filter_bank.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import Leung-Malik filters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import LM_filters\n",
    "filter_bank = LM_filters.makeLMfilters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all filters\n",
    "\n",
    "Plot the created filters as images similar to the figure above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "What are the different filters? Which is the size of the filters? How many filters there are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting a feature vector for an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Read the image ``/images/pizza.jpg``, and resize it to 240ùë•240 pixels. Then, convert the image to grayscale and visualize both, the RGB and the grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Given $D=n\\_{filters}$ filters from the filter bank and a single image `image`, make a function `get_image_features(image, filter_bank, n_filters)` that returns a feature vector of shape `n_filters`. The returned vector must contain at position $k$ the mean of the absolute value of the convolved image by filter $k$.\n",
    "\n",
    "$$\n",
    "\\text{feat}(x) = \\left( \\text{mean}( |r_1|), \\dots,\\text{mean}(|r_D|) \\right)\n",
    "$$\n",
    "\n",
    "Try the function with the previous image and print the feature vector.\n",
    "\n",
    "**Hint**: The function should return a feature vector obtained by averaging each filter response on the image. Use a small number of filters to try your functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try the function\n",
    "n_filters = 5\n",
    "im_features = get_image_features(pizza_gray, filter_bank, n_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1.3** (Optional) Try ``extract_features()`` using a different number of filters and other images (for instance ``/images/dog.jpg`` or ``/images/flower.jpg``)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Make a function `visualize_features(im,  filter_bank, n_filters=5)` that recieves the `filter_bank`, an image `im` and an integer `n_filters`. \n",
    "\n",
    "The function  must make a plot of two rows containing in the first row, in position $k$, the image convolved by filter $k$. In the second row, in position $k$, the image of the k'th filter. The result for `n_filter=5` should look like \n",
    "\n",
    "\n",
    "<img src=\"./images/filters.png\" >\n",
    "\n",
    "**Hint**: Note that since at this moment we are focusing on the texture, we will not use the color of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try the function\n",
    "visualize_features(pizza_gray, filter_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** (Optional) Try ``visualize_filters()`` using a different number of filters and using another image (for instance ``/images/dog.jpg`` or ``/images/flower.jpg``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load & resize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Read all the images in the directories, resize them to 240x240 pixels and save the image in an array:\n",
    "\n",
    "<ul>\n",
    "    <li>./images/pizza/</li>\n",
    "    <li>./images/flowers/</li>\n",
    "    <li>./images/pets/</li>\n",
    "</ul>\n",
    "\n",
    "**Hint:** You have to create an array for each directory, which containts all the images belonging to that path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "pizza_images = ...\n",
    "flowers_images = ...\n",
    "pets_images = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one image (the first) from each array. Use ``subplot`` to create a 3x1figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many images there are in each directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the matrix of the feature vectors for all images\n",
    "\n",
    "**2.2** Implement a function `get_dataset_features(all_images, filter_bank, n_filters=6)` that applies `extract_features` to get a feature vector for each of the images in the union of the three datasets (fish and chips_images, pizza, paella). It must return a matrix containing at row $k$ feature vector for the input image $k$.\n",
    "\n",
    "Try the function with the whole data set:\n",
    "\n",
    "*all_images = pizza_images + flowers_images + pets_images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing image  37\n",
      "processing image  38\n",
      "processing image  39\n",
      "processing image  40\n",
      "processing image  41\n",
      "processing image  42\n",
      "processing image  43\n",
      "processing image  44\n",
      "processing image  45\n",
      "processing image  46\n",
      "processing image  47\n",
      "processing image  48\n",
      "processing image  49\n",
      "processing image  50\n",
      "processing image  51\n",
      "processing image  52\n"
     ]
    }
   ],
   "source": [
    "## Try the function\n",
    "all_images = pizza_images + flowers_images + pets_images\n",
    "feature_vectors=get_dataset_features(all_images,  filter_bank, n_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Print the shape of `feature_vectors` as well as the features for image #3 (*i.e. all_images[3]*), image #33, and image #53, directly from the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the features of an image\n",
    "\n",
    "**2.4** Define a function `visualize_features(im_index, feature_vector)` that given three different images, plots their features. Use different colors (red, green, and blue) to distinguish the features of each image.\n",
    "Choose 3 images on your choice and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try the function\n",
    "visualize_features( [3,33,53] , feature_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** (Optional) Try the function using a different set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain which features are most important to a given image and with each derivatives are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3 Retrieving the most similar images\n",
    "\n",
    "### Similarity search\n",
    "\n",
    "Let us assume $f(x) \\in \\mathbb{R}^D$ represents a set of features for $x$. Given a query image $x$ and another image $x^m$ from the database, we can compute the distance between images as\n",
    "$$\n",
    "\\text{distance}\\left( f(x) , \\, f(x^m) \\right) = \\| \\text{feat}(x)  - \\text{feat}(x^m)  \\|_2 =  \\sqrt{ \\sum_{d=1}^\\text{D} \\left( f(x)_d - f(x^m)_d  \\right)^2 }\n",
    "$$\n",
    "\n",
    "then we can find the closest image $x^{m^*}$ from the database to $x$ as $m^* =  \\text{argmin}_{m} \\{ \\| \\text{feat}(x)  - \\text{feat}(x^m)  \\|_2 \\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3.1** Implement a function `retrieve_images(im_features, feature_vectors, k=5)` to retrieve and visualize the `k` most similar images (according to the l2 norm) to `im` and the corresponding distances.\n",
    "\n",
    "The input of this function need to be feature of the image of interest `im_features`, the whole data set features `feature_vectors`, and an integer value `k`, which defines the number of images.\n",
    "\n",
    "The function should return the ordered vector of distances and the index of the closests images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your function using ``/images/pizza.jpg``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your function\n",
    "closest, distances = retrieve_images( im_features, feature_vectors, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Write a function *show_closest_images(all_images, closest, distances)* to show the closest images and the corresponding distances. \n",
    "\n",
    "<img src=\"./images/indice.png\" >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_closest_images(all_images, closest, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** Try your function using a different number of closest images `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** (Optional) Try your function using ``/images/dog.jpg``, and ``/images/flower.jpg``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Compute the accuracy of the algorithm: given a query image. \n",
    "\n",
    "**4.1** Implement a function `accuracy(feature_vectors, class_labels, im_features, class_im,  k=5)`, which takes as input `feature_vectors`, the `class_labels` for the images (`0 = pizza`, `1 = flower` and `2 = pet`), the number of images to retrieve `k`, a query image (i.e. the feature vector for the image of interest) and the class of the query image `class_im`. \n",
    "\n",
    "Returns as output the number of retrieved images that belong to class `class_im` divided by the total of images retrieved `k` (this is the accuracy).\n",
    "\n",
    "**Hint**: Be careful to exclude the query image from the retrieved images (i.e. those cases in which `distance=0.0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc:\", accuracy(im_features, 0, feature_vectors, class_labels, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy with k=10 with the previous images. Does the accuracy match the images retrieved from the previous exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** (Optional) Try your function using other images and modifying the number of filters to be used.\n",
    "\n",
    "**Hint:** You can use `im_features = feature_vectors[j]` and `class_im = class_labels[j]`, for a given `j` value, in order to simplify the problem, instead of recomputing the features for a new image. **Remember** to exclude the query image from the retrieved images!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature normalization\n",
    "\n",
    "**4.3** As you can see in exercise 2.4, some features are higher than the rest and, therefore, they are \"more important\" during the image retrieving.\n",
    "\n",
    "Normalize each feature between **[0,1]** using the minimum and the maximum values obtained from `feature_vectors`. Note that we need to use these values to normalize `im_features`.\n",
    "\n",
    "Plot the new features of an image, using `visualize_features()`. Then, show the 5 closest images from `im_features` and compute the accuracy. Is there any difference? Do we obtain the same images than previously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc:\", accuracy(new_im_features, 0, new_feature_vectors, class_labels, k=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Image retrieval based on texture and color. \n",
    "\n",
    "**5.1** Make a function ` lm_features_rgb(rgb_image, n_bins=12)`  that returns the features based on a color descriptor (using histograms, as it was performed in the **Deliverable 3 - video segmentation**). \n",
    "\n",
    "**Hint:** How will you define it? What should be the dimensonality of the new descriptor?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your function\n",
    "lm_rgb_features = lm_features_rgb(pizza)\n",
    "print(len(lm_rgb_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Apply the function to all the images in the dataset\n",
    "\n",
    "**5.2** Using ` lm_features_rgb` build the features of all the datapoints in and save them in `lm_dataset_features`.\n",
    "\n",
    "**Hint:** You can parallelize the feature building process using `joblib.Parallel`. This will make the computation much faster if you have a processor with more than two threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "'''\n",
    "Solution\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "X_lm_rgb = joblib.Parallel(n_jobs=8)(joblib.delayed(lm_features_rgb)(im) for im in all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the accuracy of the method using lm rgb features\n",
    "\n",
    "**5.3** Compute the accuracy of the retrieved images using the features that contain color information. Make a plot of the 4 closest images to the query images in the `lm_rgb` space.\n",
    "\n",
    "Is the accuracy higher? Please, comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the accuracy of the method using a) texture, b) color and c) texture + color  features\n",
    "\n",
    "**5.4** Compute the accuracy of the retrieved images using the features that contain color information. Make a plot of the 4 closest images to the query images in the `lm_rgb` space.\n",
    "\n",
    "Is the accuracy higher? Please, comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.5** Compute the accuracy of the retrieved images using the features that contain texture and color information. Make a plot of the 4 closest images to the query images in the `lm_rgb_texture` space.\n",
    "\n",
    "Is the accuracy higher? Please, comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
