# -*- coding: utf-8 -*-
"""predict_hd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tNgf-4S7RYY-hH_lPy5hdTy3Xq_zjYsw

Heart disease prediction using Random Forests

This code is accompanied with several tips including classes, functions and methods to use. Please note that you do not have to follow these tips, but they might be handy in some cases.

Author: Polyxeni Gkontra (polyxeni.gkontra@ub.edy)
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, roc_curve
from sklearn.metrics import accuracy_score
from matplotlib import pyplot as plt

"""Read the .csv file with the patient information (TIP: you can use read_csv function from pandas) """



"""Explore your data. E.g. Print the file or few lines to see how it looks like (TIP: If you want to see just few lines consider function head(). Functions dtypes() and describe() are useful to check the type of the data in each column and statistical properties, respectively)"""



"""Check statistical details on your data like counts, min, max etc"""



"""Check the type of the features"""



"""Check how many patients you have from each category

Split your dataset into training and testing creating a balanced dataset (TIP: 1. You can drop patients from the majority class, 2. You can use from scikit-learn, train_test_split(), 3. Good ML practices suggest to always shuffle your data, for dataframes you can use sample but watch out to add reset_index(drop=True) to reset the idnex but avoid creating a column with the index)
"""



"""Data pre-processing 

1.   Encode categorical variables  (TIP: Check OrdinalEncoder() from sklearn.preprocessing. Another popular approaches is OneHotEncoder but not appropriate for tree based classifiers, can you imagine why?)
2.   Scale numerical data (TIP: Check MinMaxScaler())

TIP: 1. It is very important to treat testing and training data separately to avoid data leakage 2. Methods fit_transform (for training data) and tranfrom (for the testing data) from can be very helpful. Alternatively you can use Pipeline and ColumnTransformer from sklearn but it will be more complicated to retrieve feature names for the most important features


"""



"""Train the model (TIP: Check method fit)"""



"""Apply the model to the testing data and evaluate its perfromance (TIP: You might use classification_report or roc_auc_score)"""



"""Get the feature importance in the model's estimation and plot the most important features (TIP: To get feature importance and names you can use feature_importances_ and feature_names_in attributes of your model, respectively)"""

